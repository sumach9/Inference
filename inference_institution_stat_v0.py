# -*- coding: utf-8 -*-
"""Inference_institution_stat_v0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AWbruPG9NGQSPHpjhZqoebAPRBYF9Y2l

Data Science Team Notebook - [Inference] - [Online search of education related statistics via language_agent_tree_search method (langchain)]
-----------------------------------------------------------
Author(s): [Anna Sviripa
Date: [2025-04-09]
Version: 0.0

Module Description:
    This notebook/module is part of the Inference project and implements online search of education related statistics via language_agent_tree_search method (langchain).
    Final output of this notebook is to be used in calculating the score for the "MATCH_TBD" fields

    The module can be divided into the following major steps:
        1. Data Extraction and preprocessing from json
        2. Search online for the information
        3. Extraction of values from the LLM response via OpenAI


Assumptions:
    - The dataset is assumed to be populated with existing universities.

Dependencies:
    - Python version: [e.g., Python 3.8]
    - Libraries:
        subprocess
        sys
        getpass
        os
        math
        collections
        typing
        langchain_core.messages
        pydantic
        langchain_openai
        typing_extensions
        langchain_community.utilities
        langchain_core.tools
        langgraph.prebuilt
        langchain_core.output_parsers.openai_tools
        langchain_core.prompts
        langchain_core.runnables
        typing
        langgraph.graph
        langchain_core.prompt_values
        langchain_core.runnables
        collections
        language_agent_tree_search
        import json
        datetime import datetime

File Structure:
    - language_agent_tree_search.py is loaded from the FFP_B2B_DS_POC/Inference folder
"""

# Commented out IPython magic to ensure Python compatibility.
# This is required to load "from language_agent_tree_search import tree_search_answer"
# Use your actual GitHub username and personal access token
# from getpass import getpass

# This keeps your token hidden
# token = getpass('Enter your GitHub personal access token: ')

# !git clone https://USERNAME:$token@github.com/FactFindersPro1/FFP_B2B_DS_POC.git
# 
# Move into your repo
# %cd FFP_B2B_DS_POC/Inference

# Commented out IPython magic to ensure Python compatibility.
# %%capture --no-stderr
# %pip install -U --quiet langchain langgraph langchain_openai
# %pip install -U --quiet tavily-python
# %pip install -U langchain langchain-community
# %pip install -U duckduckgo-search

from language_agent_tree_search import tree_search_answer
import json
from datetime import datetime
import openai

#Data

"""## Data Extraction and preprocessing from json"""

def find_tbd_school(example_certification) :


  school_year_list = []

  for record in example_certification["person_of_interest"]["education"]:
      found_match_tbd = False

      # Check degree title
      if record.get("degree_title", {}).get("comparison_result") == "MATCH_TBD":
          found_match_tbd = True

      # Check major and minor fields
      for field in ["major", "minor", "academic_honors"]:
          for item in record.get(field, []):
              if item.get("comparison_result") == "MATCH_TBD":
                  found_match_tbd = True

      # Check honors_program
      if record.get("honors_program", {}).get("comparison_result") == "MATCH_TBD":
          found_match_tbd = True

      # Check start_date
      start_date_info = record.get("dates_of_attendance", {}).get("start_date", {})
      start_date_value = start_date_info.get("value", "")
      try:
          year = datetime.strptime(start_date_value, "%B %d, %Y").year
      except ValueError:
          try:
              year = datetime.strptime(start_date_value, "%b %d, %Y").year
          except ValueError:
              year = None

      if found_match_tbd and year:
          school_name = record["school_name"]["value"]
          school_year_list.append([school_name, year])

  return school_year_list



"""## Search online for the information"""

def search_online(school_year_list):

  tree_answer_list = []
  for ind_school in range(len(school_year_list)):
      template = "Find average acceptance rate for {} in {}. If you cannot find info for year {}, search for a single nearest year you can find. It is possible that mentioned univesity does not exist."
  # Unpack first list item
      school, year = school_year_list[ind_school]
  # Format the string
      query = template.format(school, year, year)

      tree_answer_list.append(tree_search_answer(query))
  return tree_answer_list





openai.api_key = "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"

"""## Extraction of values from the LLM response via OpenAI  """

def get_chat_response(prompt):
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": 'Your task is to look at each statement about acceptance rates which are represented in %, convert it to its decimal form (0.0-1.0) and report back a single value for each university, separated by a comma. If no acceptance rate provided, return 0.0. Example output: {"university_name": 0.20}'},
            {"role": "user", "content": prompt}
        ],
        temperature=0.0
    )
    return response.choices[0].message.content

def get_acceptance_rate(tree_answer_list):

  final_stats = {}
  for ind_tree_answer in range(len(tree_answer_list)):
      output = get_chat_response(tree_answer_list[ind_tree_answer])
      final_stats.update(json.loads(output))
  return final_stats

"""The final array of values to be plugged into posterior"""

def get_institution_stats(example_certification):

  school_year_list = find_tbd_school(example_certification)
  tree_answer_list = search_online(school_year_list)
  return get_acceptance_rate(tree_answer_list)






